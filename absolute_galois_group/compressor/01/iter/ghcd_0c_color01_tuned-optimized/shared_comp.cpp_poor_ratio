/**
 * Galois-DCT Hybrid Compressor (GDHC) - v10.3 "Metadata Resilience"
 * * PRODUCTION READY INTEGRATION
 * - Fixed: Serialization mismatch when changing block sizes (Metadata Header).
 * - Fixed: uint16_t Dictionary Indexing.
 * - Fixed: Memory safety for variable block sizes.
 * - Feature: Dual-Layer Quadtree (Base + Residual).
 * - Feature: Crypto-Morphism Morphing.
 * - Storage: Zlib compressed bitstream.
 */

#include <iostream>
#include <fstream>
#include <vector>
#include <cmath>
#include <algorithm>
#include <string>
#include <sstream>
#include <cstdint>
#include <cfloat>
#include <random>
#include <map>
#include <iomanip>
#include <Eigen/Dense>
#include <boost/iostreams/filtering_streambuf.hpp>
#include <boost/iostreams/copy.hpp>
#include <boost/iostreams/filter/zlib.hpp>

using namespace Eigen;
using namespace std;

const int CANONICAL_SIZE = 8; 

struct CompressionConfig {
    int base_block_size = 16;
    int resid_block_size = 8;
    int base_entries = 1024;      
    int resid_entries = 2048;    
    float base_var_threshold = 40.0f; 
    float resid_var_threshold = 10.0f;
    float lambda_base = 120.0f;
    float lambda_resid = 30.0f;
    int crypto_trials = 64;
};

enum QTNodeType : uint8_t { QT_LEAF = 0, QT_SPLIT = 1 };

#pragma pack(push,1)
struct FieldEntry { 
    uint16_t id = 0;        
    uint16_t morphism = 0;  
    uint8_t offset = 0;     
    uint8_t gain = 0;       
};
#pragma pack(pop)

struct RDOStats {
    float ssd = FLT_MAX;
    float bits = 0;
    std::string stream;
};

// --- Math & Resizing ---

MatrixXf resize_matrix(const MatrixXf& src, int target_size) {
    if (src.rows() == target_size && src.cols() == target_size) return src;
    MatrixXf dst(target_size, target_size);
    float scale_r = (float)src.rows() / target_size;
    float scale_c = (float)src.cols() / target_size;

    for (int r = 0; r < target_size; ++r) {
        for (int c = 0; c < target_size; ++c) {
            float sr_f = r * scale_r;
            float sc_f = c * scale_c;
            int sr = std::min((int)sr_f, (int)src.rows() - 1);
            int sc = std::min((int)sc_f, (int)src.cols() - 1);
            
            if (scale_r >= 1.0f) {
                int r_limit = std::min((int)scale_r, (int)src.rows() - sr);
                int c_limit = std::min((int)scale_c, (int)src.cols() - sc);
                dst(r,c) = src.block(sr, sc, r_limit, c_limit).mean();
            } else {
                dst(r,c) = src(sr, sc); 
            }
        }
    }
    return dst;
}

// --- Transformation Engine ---

class CryptoMorphismEngine {
public:
    static MatrixXf apply(const MatrixXf& src, uint16_t key) {
        if (key < 16) return apply_geometric(src, key);
        int rows = src.rows(), cols = src.cols(), n = rows * cols;
        MatrixXf dst(rows, cols);
        std::mt19937 rng(key);
        std::vector<int> indices(n);
        std::iota(indices.begin(), indices.end(), 0);
        std::shuffle(indices.begin(), indices.end(), rng);
        const float* src_ptr = src.data(); 
        float* dst_ptr = dst.data();
        for(int i=0; i<n; ++i) dst_ptr[i] = src_ptr[indices[i]];
        return dst;
    }
private:
    static MatrixXf apply_geometric(const MatrixXf& block, uint16_t m) {
        MatrixXf res;
        bool negate = (m & 8);
        uint8_t op = m & 7;
        switch(op) {
            case 0: res = block; break;
            case 1: res = block.reverse(); break;
            case 2: res = block.rowwise().reverse(); break;
            case 3: res = block.colwise().reverse(); break;
            case 4: res = block.transpose(); break;
            case 5: res = block.transpose().reverse(); break;
            case 6: res = block.transpose().rowwise().reverse(); break;
            case 7: res = block.transpose().colwise().reverse(); break;
            default: res = block;
        }
        return negate ? (-res).eval() : res;
    }
};

// --- Dictionary Management ---

class ManifoldDictionary {
public:
    vector<MatrixXf> atoms;
    void train(const MatrixXf &data, int block_size, int max_entries, float min_var) {
        atoms.clear();
        struct Candidate { MatrixXf m; float var; };
        vector<Candidate> pool;
        if (data.rows() < block_size || data.cols() < block_size) return;

        for(int i=0; i <= data.rows()-block_size; i+=block_size) {
            for(int j=0; j <= data.cols()-block_size; j+=block_size) {
                MatrixXf b = data.block(i,j,block_size,block_size);
                MatrixXf b_centered = b.array() - b.mean();
                float v = b_centered.squaredNorm();
                if (v < min_var) continue;
                MatrixXf canon = resize_matrix(b_centered, CANONICAL_SIZE);
                float n = canon.norm();
                if (n > 1e-5) pool.push_back({canon/n, v});
            }
        }
        if (pool.empty()) return;
        std::sort(pool.begin(), pool.end(), [](auto& a, auto& b){ return a.var > b.var; });
        atoms.push_back(pool[0].m);
        for(size_t i=1; i < pool.size() && atoms.size() < (size_t)max_entries; ++i) {
            float min_d = 1e9;
            for(const auto& a : atoms) min_d = std::min(min_d, (pool[i].m - a).norm());
            if(min_d > 0.35f) atoms.push_back(pool[i].m);
        }
    }
    FieldEntry solve(const MatrixXf &target, float &scale, int max_trials) {
        FieldEntry best; scale = 0.0f;
        if(atoms.empty()) return best;
        MatrixXf t_canon = resize_matrix(target, CANONICAL_SIZE);
        float tnorm = t_canon.norm();
        if(tnorm < 1e-6f) return best;
        t_canon /= tnorm; 
        float best_corr = -1.0f;
        for(uint16_t i=0; i < (uint16_t)atoms.size(); ++i){
            for(uint16_t m=0; m < 16; ++m){
                MatrixXf cand = CryptoMorphismEngine::apply(atoms[i], m);
                float corr = (cand.array() * t_canon.array()).sum();
                if(corr > best_corr){ best_corr = corr; best.id = i; best.morphism = m; }
            }
        }
        scale = best_corr * tnorm; 
        return best;
    }
};

// --- Image I/O ---

struct Image3 { 
    int width=0, height=0; 
    std::vector<MatrixXf> channels;
    Image3() { channels.resize(3); }
};

Image3 loadPPM(const string& filename) {
    ifstream in(filename, ios::binary);
    if (!in) throw runtime_error("File error");
    string magic; in >> magic;
    int w, h, max_val; in >> w >> h >> max_val;
    in.ignore();
    Image3 img; img.width = w; img.height = h;
    for(int k=0; k<3; ++k) img.channels[k].resize(h, w);
    vector<uint8_t> buf(w * 3);
    for(int i=0; i<h; ++i) {
        in.read((char*)buf.data(), w * 3);
        for(int j=0; j<w; ++j) {
            img.channels[0](i,j) = buf[j*3];
            img.channels[1](i,j) = buf[j*3+1];
            img.channels[2](i,j) = buf[j*3+2];
        }
    }
    return img;
}

void savePPM(const string& filename, const Image3& img) {
    ofstream out(filename, ios::binary);
    out << "P6\n" << img.width << " " << img.height << "\n255\n";
    vector<uint8_t> buf(img.width * 3);
    for(int i=0; i<img.height; ++i) {
        for(int j=0; j<img.width; ++j) {
            buf[j*3]   = (uint8_t)std::clamp(img.channels[0](i,j), 0.0f, 255.0f);
            buf[j*3+1] = (uint8_t)std::clamp(img.channels[1](i,j), 0.0f, 255.0f);
            buf[j*3+2] = (uint8_t)std::clamp(img.channels[2](i,j), 0.0f, 255.0f);
        }
        out.write((char*)buf.data(), img.width * 3);
    }
}

// --- Quadtree Engine ---

RDOStats compress_quadtree(const MatrixXf &src, int r, int c, int size, 
                           ManifoldDictionary &dict, MatrixXf &recon_out, 
                           float lambda, int crypto_trials, bool allow_split, int min_split_size) {
    RDOStats res;
    int h_eff = std::min(size, (int)src.rows() - r);
    int w_eff = std::min(size, (int)src.cols() - c);
    if (h_eff <= 0 || w_eff <= 0) return res;

    MatrixXf blk = src.block(r, c, h_eff, w_eff);
    float mu = blk.mean();
    float scale_found = 0;
    FieldEntry e = dict.solve(blk.array() - mu, scale_found, crypto_trials);
    e.offset = (uint8_t)std::clamp(mu + 128.0f, 0.0f, 255.0f);
    float q_step = 0.5f; 
    e.gain = (uint8_t)std::clamp(std::abs(scale_found) / q_step, 0.0f, 255.0f);

    MatrixXf atom = MatrixXf::Zero(size, size);
    if (e.id < dict.atoms.size()) {
        atom = resize_matrix(CryptoMorphismEngine::apply(dict.atoms[e.id], e.morphism), size);
        if (scale_found < 0) atom = -atom;
        float n = atom.norm();
        if (n > 1e-6f) atom *= ((float)e.gain * q_step / n);
    }
    
    MatrixXf leaf_recon = (atom.array() + (float)(e.offset - 128)).matrix().block(0,0,h_eff,w_eff);
    float ssd = (blk - leaf_recon).squaredNorm();
    float bits = (float)sizeof(FieldEntry) * 8.0f;
    float cost = ssd + lambda * bits;

    if (allow_split && size > min_split_size) {
        int half = size / 2;
        RDOStats ch[4];
        float split_ssd = 0, split_bits = 4.0f;
        for(int i=0; i<4; i++) {
            ch[i] = compress_quadtree(src, r+(i/2)*half, c+(i%2)*half, half, dict, recon_out, lambda, crypto_trials, true, min_split_size);
            split_ssd += ch[i].ssd; split_bits += ch[i].bits;
        }
        if (split_ssd + lambda * split_bits < cost) {
            res.ssd = split_ssd; res.bits = split_bits;
            uint8_t flag = QT_SPLIT; res.stream.append((char*)&flag, 1);
            for(int i=0; i<4; i++) res.stream.append(ch[i].stream);
            return res;
        }
    }
    recon_out.block(r, c, h_eff, w_eff) = leaf_recon;
    res.ssd = ssd; res.bits = bits;
    if (allow_split) { uint8_t flag = QT_LEAF; res.stream.append((char*)&flag, 1); }
    res.stream.append((char*)&e, sizeof(FieldEntry));
    return res;
}

void decode_quadtree(stringstream &ss, MatrixXf &target, int r, int c, int size, 
                     const vector<MatrixXf> &atoms, bool allow_split) {
    if (allow_split) {
        uint8_t flag = 0;
        if (!ss.read((char*)&flag, 1)) return;
        if (flag == QT_SPLIT) {
            int h = size/2;
            decode_quadtree(ss, target, r, c, h, atoms, true);
            decode_quadtree(ss, target, r, c+h, h, atoms, true);
            decode_quadtree(ss, target, r+h, c, h, atoms, true);
            decode_quadtree(ss, target, r+h, c+h, h, atoms, true);
            return;
        }
    }
    FieldEntry e; if (!ss.read((char*)&e, sizeof(FieldEntry))) return;
    int he = std::min(size, (int)target.rows()-r), we = std::min(size, (int)target.cols()-c);
    if (he <= 0 || we <= 0) return;
    float q = 0.5f;
    if (e.id < atoms.size()) {
        MatrixXf atom = resize_matrix(CryptoMorphismEngine::apply(atoms[e.id], e.morphism), size);
        float n = atom.norm();
        if (n > 1e-6f) atom *= ((float)e.gain * q / n);
        target.block(r, c, he, we) += (atom.array() + (float)(e.offset - 128)).matrix().block(0,0,he,we);
    } else {
        target.block(r, c, he, we) += MatrixXf::Constant(he, we, (float)(e.offset - 128));
    }
}

// --- Main Logic ---

void run_compression(const string &input, const string &output, const CompressionConfig &cfg) {
    Image3 img = loadPPM(input);
    stringstream bitstream;
    
    // --- METADATA HEADER (CRITICAL FOR PRODUCTION) ---
    uint32_t magic = 0x47444843; // "GDHC"
    bitstream.write((char*)&magic, 4);
    bitstream.write((char*)&img.width, 4);
    bitstream.write((char*)&img.height, 4);
    bitstream.write((char*)&cfg.base_block_size, 4);
    bitstream.write((char*)&cfg.resid_block_size, 4);

    ManifoldDictionary b_dict, r_dict;
    Image3 recon_base; recon_base.width = img.width; recon_base.height = img.height;

    for(int k=0; k<3; ++k) {
        b_dict.train(img.channels[k], cfg.base_block_size, cfg.base_entries, cfg.base_var_threshold);
        uint32_t n_b = b_dict.atoms.size();
        bitstream.write((char*)&n_b, 4);
        for(auto &a : b_dict.atoms) bitstream.write((char*)a.data(), a.size()*sizeof(float));

        recon_base.channels[k] = MatrixXf::Zero(img.height, img.width);
        for(int i=0; i<img.height; i+=cfg.base_block_size) {
            for(int j=0; j<img.width; j+=cfg.base_block_size) {
                auto rdo = compress_quadtree(img.channels[k], i, j, cfg.base_block_size, b_dict, recon_base.channels[k], cfg.lambda_base, cfg.crypto_trials, true, cfg.base_block_size/2);
                uint32_t sz = rdo.stream.size();
                bitstream.write((char*)&sz, 4);
                bitstream.write(rdo.stream.data(), sz);
            }
        }

        MatrixXf residual = img.channels[k] - recon_base.channels[k];
        r_dict.train(residual, cfg.resid_block_size, cfg.resid_entries, cfg.resid_var_threshold);
        uint32_t n_r = r_dict.atoms.size();
        bitstream.write((char*)&n_r, 4);
        for(auto &a : r_dict.atoms) bitstream.write((char*)a.data(), a.size()*sizeof(float));

        MatrixXf dummy = MatrixXf::Zero(img.height, img.width);
        for(int i=0; i<img.height; i+=cfg.resid_block_size) {
            for(int j=0; j<img.width; j+=cfg.resid_block_size) {
                auto rdo = compress_quadtree(residual, i, j, cfg.resid_block_size, r_dict, dummy, cfg.lambda_resid, cfg.crypto_trials, false, cfg.resid_block_size);
                bitstream.write(rdo.stream.data(), rdo.stream.size());
            }
        }
    }
    ofstream fout(output, ios::binary);
    boost::iostreams::filtering_streambuf<boost::iostreams::output> out_f;
    out_f.push(boost::iostreams::zlib_compressor());
    out_f.push(fout);
    boost::iostreams::copy(bitstream, out_f);
}

void run_decompression(const string &input, const string &output) {
    ifstream fin(input, ios::binary);
    boost::iostreams::filtering_streambuf<boost::iostreams::input> in_f;
    in_f.push(boost::iostreams::zlib_decompressor());
    in_f.push(fin);
    stringstream ss;
    boost::iostreams::copy(in_f, ss);

    uint32_t magic; ss.read((char*)&magic, 4);
    if (magic != 0x47444843) return;
    int w, h, b_size, r_size;
    ss.read((char*)&w, 4); ss.read((char*)&h, 4);
    ss.read((char*)&b_size, 4); ss.read((char*)&r_size, 4);

    Image3 out; out.width = w; out.height = h;
    for(int k=0; k<3; ++k) {
        out.channels[k] = MatrixXf::Zero(h, w);
        uint32_t n_b; ss.read((char*)&n_b, 4);
        vector<MatrixXf> b_atoms(n_b, MatrixXf::Zero(CANONICAL_SIZE, CANONICAL_SIZE));
        for(auto &a : b_atoms) ss.read((char*)a.data(), a.size()*sizeof(float));
        for(int i=0; i<h; i+=b_size) {
            for(int j=0; j<w; j+=b_size) {
                uint32_t sz; ss.read((char*)&sz, 4);
                string sub(sz, '\0'); ss.read(&sub[0], sz);
                stringstream sub_ss(sub);
                decode_quadtree(sub_ss, out.channels[k], i, j, b_size, b_atoms, true);
            }
        }
        uint32_t n_r; ss.read((char*)&n_r, 4);
        vector<MatrixXf> r_atoms(n_r, MatrixXf::Zero(CANONICAL_SIZE, CANONICAL_SIZE));
        for(auto &a : r_atoms) ss.read((char*)a.data(), a.size()*sizeof(float));
        for(int i=0; i<h; i+=r_size) {
            for(int j=0; j<w; j+=r_size) {
                decode_quadtree(ss, out.channels[k], i, j, r_size, r_atoms, false);
            }
        }
    }
    savePPM(output, out);
}




// --- ARGUMENT PARSER ---

void print_help(const char* prog) {
    cout << "Usage: " << prog << " <mode:c/d> <input.ppm/bin> <output> [options]\n"
         << "Options:\n"
         << "  --base-block <int>    Size of base layer blocks (default: 16)\n"
         << "  --resid-block <int>   Size of residual micro-blocks (default: 4)\n"
         << "  --base-entries <int>  Dictionary size for base layer (default: 128)\n"
         << "  --resid-entries <int> Dictionary size for residual layer (default: 256)\n"
         << "  --lambda-base <float> RDO Lambda for base (higher=less bits) (default: 150.0)\n"
         << "  --lambda-resid <float> RDO Lambda for residual (default: 20.0)\n"
         << "  --base-var <float>    Min variance to learn base atom (default: 100.0)\n"
         << "  --resid-var <float>   Min variance to learn residual atom (default: 10.0)\n"
         << "  --base-entries <int>  Dictionary size for base layer (default: 128)\n"
         << "  --resid-entries <int> Dictionary size for residual layer (default: 256)\n"
         << "  --crypto-trials <int> Random permutation trials per block (default: 64)\n";
}

int main(int argc, char** argv) {
    if(argc < 4) { print_help(argv[0]); return 1; }

    string mode = argv[1];
    string in_file = argv[2];
    string out_file = argv[3];

    CompressionConfig cfg;

    // Parse tunable parameters
    for(int i=4; i<argc; ++i) {
        string arg = argv[i];
        if(i+1 >= argc) break; 
        
        try {
            if(arg == "--base-block") cfg.base_block_size = stoi(argv[++i]);
            else if(arg == "--resid-block") cfg.resid_block_size = stoi(argv[++i]);
            else if(arg == "--base-entries") cfg.base_entries = stoi(argv[++i]);
            else if(arg == "--resid-entries") cfg.resid_entries = stoi(argv[++i]);
            else if(arg == "--lambda-base") cfg.lambda_base = stof(argv[++i]);
            else if(arg == "--lambda-resid") cfg.lambda_resid = stof(argv[++i]);
            else if(arg == "--base-var") cfg.base_var_threshold = stof(argv[++i]);
            else if(arg == "--resid-var") cfg.resid_var_threshold = stof(argv[++i]);
            else if(arg == "--crypto-trials") cfg.crypto_trials = stoi(argv[++i]);
        } catch(...) {
            cerr << "Invalid value for argument: " << arg << endl;
            return 1;
        }
    }

    if(mode == "c") run_compression(in_file, out_file, cfg);
    else if(mode == "d") run_decompression(in_file, out_file); 
    else { cerr << "Unknown mode: " << mode << endl; return 1; }

    return 0;
}
